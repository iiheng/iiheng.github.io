---
title: 分布式爬虫
date: 2022-03-27 21:47:19
tags:
---
## 前言
## 分布式爬虫理念
## 将Scrapy项目打包成Docker镜像
### 准备工作
### 创建Dockerfile
`git clone https://github.com/Python3WebSpider/ScrapyCompositeDemo.git`

### 创建 Dockerfile
```
scrapy>=2.0.0
aiohttp
scrapy-redis
environs
```

```
FROM python:3.7
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt -i https://pypi.douban.com/simple
COPY . .
CMD ["scrapy","crawl","book"]
```

```
import os
accountpool_url = os.getenv("ACCOUNTPOOL_URL")
proxypool_url = os.getenv("PROXYPOOL_URL")
```

```
import os
REDIS_URL = os.getenv("REDIS_URL")
```

`docker build -t scrapycompositedemo`
`docker images`

```
ACCOUNTPOOL_URL=http://host.docker.internal:6777/antispider7/random
PROXYPOOL_URL=http://host.docker.internal:5555/random
REDIS_URL=redis://host.docker.internal:6379
```

`docker login`
`docker tag scrapycompositedemo:latest 1269305589/scrapycompositedemo:latest`

`docker run --env-file .env 1269305589/scrapycompositedemo`
### 总结
## Docker Compose 的使用
### Docker Compose
### 准备工作
### 创建YAML文件
```
version: "3"
services: 
  redis: 
    image: redis:alpine
    container_name: redis
    ports: 
     - "6379"
  scrapycompositedemo: 
    build: "."
    image: "1269305589/scrapycompositedemo"
    environment: 
      ACCOUNTPOOL_URL: "http://host.docker.internal:6777/antispider7/random"
      PROXYPOOL_URL: "http://host.docker.internal:5555/random"
      REDIS_HOST: "redis://redis:6379"
    depends_on: 
      - redis
```

### 构建镜像
`docker-compose build`
### 运行镜像
`docker-compose up`
### 推送镜像
`docker-compose push`